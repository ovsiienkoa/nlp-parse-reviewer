{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "name": "inference-embeddinggemma-with-sentence-transformers.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 13489048,
     "sourceType": "datasetVersion",
     "datasetId": 8564266
    }
   ],
   "dockerImageVersionId": 31153,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install -U sentence-transformers git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview -q",
   "metadata": {
    "_uuid": "983cf936-b2bd-4c10-9555-5e1648adf89e",
    "_cell_guid": "25fe8802-fcef-4276-8840-40d65ba1d965",
    "trusted": true,
    "collapsed": false,
    "id": "jZFuhT3nrHEK",
    "execution": {
     "iopub.status.busy": "2025-10-30T12:55:31.209131Z",
     "iopub.execute_input": "2025-10-30T12:55:31.209339Z",
     "iopub.status.idle": "2025-10-30T12:57:19.933731Z",
     "shell.execute_reply.started": "2025-10-30T12:55:31.209322Z",
     "shell.execute_reply": "2025-10-30T12:57:19.932823Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "After you have accepted the license, you need a valid Hugging Face Token to access the model.",
   "metadata": {
    "_uuid": "dbcf4f27-b722-49d3-b9d0-68bc266af9f3",
    "_cell_guid": "e64917f0-4fe3-4b26-96eb-927477e37429",
    "trusted": true,
    "collapsed": false,
    "id": "O3ttIyfSA0Lj",
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": "# Login into Hugging Face Hub\nfrom huggingface_hub import notebook_login\nnotebook_login()",
   "metadata": {
    "_uuid": "95d3b6be-0893-4e6f-ac04-74ee60b2c0dd",
    "_cell_guid": "1979afbf-e173-4efd-a780-d49dc8000473",
    "trusted": true,
    "collapsed": false,
    "id": "WXK1Ev1Sq2iY",
    "execution": {
     "iopub.status.busy": "2025-10-30T12:57:22.831501Z",
     "iopub.execute_input": "2025-10-30T12:57:22.831765Z",
     "iopub.status.idle": "2025-10-30T12:57:23.087464Z",
     "shell.execute_reply.started": "2025-10-30T12:57:22.831732Z",
     "shell.execute_reply": "2025-10-30T12:57:23.086736Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-24T19:11:48.136062Z",
     "start_time": "2025-10-24T19:11:47.936313Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "#batch triplet + random modifications\n# from datasets import load_dataset, Dataset\n# import re\n# import random\n# import numpy as np\n# class DatasetProcessor:\n\n#     def __init__(self, negative_count:int = 4, total_ratio_of_missing:float = 0.3):\n#         self.country_pattern = r\"county.*?\\n\"\n#         self.patterns = (r\"(.*?\\n)\", r\"(\\n.*? )\", r\"( .*?\\n)\", r\"( .*? )\") #patterns for removing random vals\n#         self.negative_count = negative_count\n#         self.total_ratio_of_missing = total_ratio_of_missing\n\n#     def get_masked_lines(self, line:str):\n#         \"\"\"\n#         random masking with total_ratio_of_missing and returns samples; |samples| = negative_count\n#         \"\"\"\n#         output_lines = []\n#         combs = re.findall(self.patterns[0], line)\n#         del_count = int(len(combs) * self.total_ratio_of_missing)\n#         if del_count == 0:\n#             del_count = 1\n\n#         for i in range(self.negative_count):\n#             line_in_loop = str(line)\n#             count_in_loop = del_count\n#             while count_in_loop>0:\n                \n#                 random_pattern = random.choice(self.patterns)\n#                 try:\n#                     random_value_to_drop = random.choice(re.findall(random_pattern, line_in_loop))\n#                     line_in_loop = re.sub(random_value_to_drop, \"\", line_in_loop, count=1)\n#                     count_in_loop -=1\n#                 except:\n#                     continue\n\n#             output_lines.append(line_in_loop)\n\n#         return output_lines\n\n#     def train_row_wise_changes(self, example, id):\n#         \"\"\"\n#         removes county info and applies random masking\n#         \"\"\"\n\n#         example[\"output_text\"] = re.sub(self.country_pattern, \"\", example[\"output_text\"])\n\n#         return {\n#             \"text\": [example[\"input_text\"], example[\"output_text\"]] + self.get_masked_lines(example[\"output_text\"]),\n#             \"label\": [id * (self.negative_count + 1)]*2 +list( id*(self.negative_count+ 1)+1 + np.arange(0, self.negative_count) )#unique ids for hard negatives\n#         }\n#     def test_row_wise_changes(self, example):\n#         \"\"\"\n#         removes county info and applies random masking\n#         \"\"\"\n\n#         example[\"output_text\"] = re.sub(self.country_pattern, \"\", example[\"output_text\"])\n#         example[\"failed_text\"] = self.get_masked_lines(example[\"output_text\"])\n#         return example\n\n#     @staticmethod\n#     def flatten_lists_of_lists(batch):\n#         flattened_texts = []\n#         flattened_labels = []\n\n#         for texts_lol, labels_lol in zip(batch['text'], batch['label']):\n#             flat_text = [item for item in texts_lol]\n#             flattened_texts.extend(flat_text)\n\n#             flat_label = [item for item in labels_lol]\n#             flattened_labels.extend(flat_label)\n#         return {'text': flattened_texts, 'label': flattened_labels}\n\n#     # @staticmethod\n#     # def flatten_test_of_lists(batch): #if batchtriplet\n#     #     flattened_inputs = []\n#     #     flattened_outputs = []\n#     #     flattened_fails = []\n#     #     #print(len(flattened_inputs), len(flattened_inputs), len(flattened_inputs))\n#     #     for flat_input, flat_output, fails in zip(batch['input_text'],batch['output_text'], batch['failed_text']):\n#     #         #flat_input = [item for item in input]\n#     #         flattened_inputs.extend([flat_input]*len(fails))\n\n#     #         #flat_output = [item for item in output]\n#     #         flattened_outputs.extend([flat_output]*len(fails))\n\n#     #         flat_fail = [item for item in fails]\n#     #         flattened_fails.extend(flat_fail)\n\n#     #     return {'input_text': flattened_inputs, 'output_text': flattened_outputs, \"failed_text\":flattened_fails}\n\n#     @staticmethod\n#     def flatten_test_of_lists(batch): #if contrastive\n#         flattened_inputs = []\n#         flattened_outputs = []\n#         flattened_labels = []\n\n#         for flat_input, flat_output, fails in zip(batch['input_text'],batch['output_text'], batch['failed_text']):\n\n#             flattened_inputs.extend([flat_input]*(len(fails)+1))\n#             flattened_output = [flat_output] + [item for item in fails]\n#             flattened_outputs.extend(flattened_output)\n#             flattened_labels.extend([1]*len([flat_output]) + [0]*len(fails))\n            \n#         return {'input_text': flattened_inputs, 'output_text': flattened_outputs, \"failed_text\":[None]*len(flattened_labels),\"label\":flattened_labels}\n#     def process(self, dataset:Dataset):\n#         \"\"\"\n#         train_test split, all data permutation applied with class methods\n#         \"\"\"\n#         dataset = dataset.select_columns(['input_text', 'output_text', 'output_empty', 'label'])\n#         dataset = dataset.filter(lambda example: (example[\"output_empty\"] == False) & (example[\"label\"] == 1))\n#         dataset = dataset.select_columns(['input_text', 'output_text'])\n#         #if contrastive\n#         dataset = dataset.map(self.test_row_wise_changes)\n#         #------\n#         dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n#         #------\n#         new_dataset = dataset.map(self.flatten_test_of_lists, batched = True).select_columns(['input_text', 'output_text', 'label']) \n        \n#         #if batchtriplet\n#         #train_subset = dataset[\"train\"].map(self.train_row_wise_changes, with_indices=True)\n#         #train_subset = train_subset.select_columns(['text', 'label']) #if batchtriplet\n#         #test_subset = dataset[\"test\"].map(self.test_row_wise_changes)\n#         #new_dataset = {\"train\": train_subset.map(self.flatten_lists_of_lists, batched=True), \n#                        #\"test\": test_subset.map(self.flatten_test_of_lists, batched=True),}\n#         #new_dataset = new_dataset[\"train\"].train_test_split(test_size=0.2)\n        \n#         return new_dataset\n\n# ds_proc = DatasetProcessor(negative_count = 5, total_ratio_of_missing=0.2)\n# raw_ds = load_dataset('json', data_files='/kaggle/input/nlp-corpus-haystack/dataset.jsonl')\n# new_ds = ds_proc.process(raw_ds)",
   "metadata": {
    "_uuid": "8dc74c24-1a3f-4e3c-b8d7-a19f30d77518",
    "_cell_guid": "d99302ba-5257-4de8-b52c-7737cf076a52",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-27T10:58:00.481521Z",
     "iopub.execute_input": "2025-10-27T10:58:00.481822Z",
     "iopub.status.idle": "2025-10-27T10:58:03.372214Z",
     "shell.execute_reply.started": "2025-10-27T10:58:00.481800Z",
     "shell.execute_reply": "2025-10-27T10:58:03.371433Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-24T19:12:03.712432Z",
     "start_time": "2025-10-24T19:11:59.796480Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# #if you lack of VRAM then you can't use large batchtriplet, instead we will small one. also youcan consider use contrastive with low batch (BYOL says that it's bad approach)\n# def reorder_dataset_columns(original_text_list, original_label_list):\n\n#     new_text = []\n#     new_label = []\n#     prev_X = None\n#     prev_T = None\n\n#     # Iterate over the data in chunks of 3\n#     for i in range(0, len(original_label_list), 3):\n#         text_chunk = original_text_list[i:i+3]\n#         label_chunk = original_label_list[i:i+3]\n\n#         if (i // 3) % 2 == 0:\n#             label_chunk = [1, 1, 0]\n#             prev_X = label_chunk[0]\n#             prev_T = text_chunk[0]\n\n#             new_label.extend(label_chunk)\n#             new_text.extend(text_chunk)\n            \n#         else:            \n#             if prev_X is None or prev_T is None:\n#                 new_label.extend(label_chunk)\n#                 new_text.extend(text_chunk)\n#                 continue\n                \n#             for l_j, t_j in zip(label_chunk, text_chunk):\n#                 # Append the constant label (prev_X) twice, then the element's label (l_j)\n#                 new_label.extend([1, 1, 0])\n                \n#                 # Append the constant text (prev_T) twice, then the element's text (t_j)\n#                 new_text.extend([prev_T, prev_T, t_j])\n\n#     return new_text, new_label\n\n# new_text_list, new_label_list = reorder_dataset_columns(new_ds[\"train\"][\"text\"], new_ds[\"train\"][\"label\"])\n\n# new_ds[\"train\"] = Dataset.from_dict({'text': new_text_list, 'label': new_label_list})",
   "metadata": {
    "_uuid": "fdfa1027-4a81-43cb-9db3-29948f7cb940",
    "_cell_guid": "728a9ab0-1234-4214-adaa-26a9b25815cb",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-27T10:58:03.373678Z",
     "iopub.execute_input": "2025-10-27T10:58:03.374018Z",
     "iopub.status.idle": "2025-10-27T10:58:03.377882Z",
     "shell.execute_reply.started": "2025-10-27T10:58:03.373998Z",
     "shell.execute_reply": "2025-10-27T10:58:03.377316Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from datasets import load_dataset\nimport numpy as np\nraw_ds = load_dataset('json', data_files='/kaggle/input/nlp-corpus-haystack/dataset.jsonl')  #/kaggle/input/nlp-corpus-haystack/dataset.jsonl\n\ndef process_input(example):\n    example[\"input_text\"] += f'\\nsection: {example[\"section\"]},\\ncounty: {example[\"county\"]},\\nparcel_id: {example[\"parcel_id\"]}'\n    #example[\"output_text\"] = re.sub(r\"county.*?\\n\", \"\", example[\"output_text\"])\n    return example\n\ndef process_ds(dataset):\n    #dataset = dataset.select_columns(['input_text', 'output_text', 'output_empty', 'label'])\n    #dataset = dataset.filter(lambda example: example[\"output_empty\"] == False)\n    dataset = dataset.map(process_input)\n    dataset = dataset.select_columns(['input_text', 'output_text', 'label'])\n    \n    return dataset\n\ncos_ds = process_ds(raw_ds[\"train\"])\n\n#train_test_split without data leakage\nfrom sklearn.model_selection import train_test_split\nfrom datasets import DatasetDict\nids = np.arange(len(cos_ds))[:-1:2]\ntrain_id, test_id = train_test_split(\n    ids,\n    train_size=0.8,\n    random_state=42\n)\n\nrng = np.random.default_rng(seed = 42)\ntrain_id_adj = train_id + 1\ntrain_id = np.append(train_id, train_id_adj)\nrng.shuffle(train_id)\ntest_id_adj = test_id + 1\ntest_id  = np.append(test_id, test_id_adj)\nrng.shuffle(test_id)\ncos_alt_ds = DatasetDict({\n    \"train\": cos_ds.select(train_id),\n    \"test\": cos_ds.select(test_id)\n})\ncos_ds = cos_alt_ds\ncos_eval = cos_ds[\"test\"]\n#\n\n# cos_ds = cos_ds.train_test_split(test_size=0.2, seed = 42) #possible data leakage\n# cos_eval = cos_ds[\"test\"]",
   "metadata": {
    "_uuid": "7dac129e-e4b6-46ba-ab04-5d6a1e8b7282",
    "_cell_guid": "e13dfa13-7d69-4dbc-b864-eb6231ac0723",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T12:57:33.599737Z",
     "iopub.execute_input": "2025-10-30T12:57:33.600325Z",
     "iopub.status.idle": "2025-10-30T12:57:35.813690Z",
     "shell.execute_reply.started": "2025-10-30T12:57:33.600301Z",
     "shell.execute_reply": "2025-10-30T12:57:35.812919Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T11:17:35.804752Z",
     "start_time": "2025-10-30T11:17:34.018818Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "print(np.sort(test_id)[:7])\nnp.any(np.isin(train_id, test_id))",
   "metadata": {
    "_uuid": "4811ae3e-fd55-484a-ba86-ae2029b418f0",
    "_cell_guid": "231d1933-c6a4-4650-a9d2-e1072916ab73",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T12:57:35.815280Z",
     "iopub.execute_input": "2025-10-30T12:57:35.815815Z",
     "iopub.status.idle": "2025-10-30T12:57:35.823834Z",
     "shell.execute_reply.started": "2025-10-30T12:57:35.815786Z",
     "shell.execute_reply": "2025-10-30T12:57:35.823034Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T11:17:36.409588Z",
     "start_time": "2025-10-30T11:17:36.397808Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import random\nrandom.seed(42)\n\ndef country_change(example):\n    counties_to_sample = ['Autauga', 'Cook', 'Harris', 'Maricopa', 'San Diego', 'Orange', 'Collier', 'Kings', 'Dallas']\n    states_to_sample = ['AL', 'IL', 'TX', 'AZ', 'CA', 'CA', 'FL', 'NY', 'TX']\n    #change county in each row\n    idx = list(range(len(counties_to_sample)))\n    sample_id = random.choice(idx)\n    example[\"input_text\"] = example[\"input_text\"].replace(\"Collier\", counties_to_sample[sample_id])\n    example[\"input_text\"] = example[\"input_text\"].replace(\"FL\", states_to_sample[sample_id])\n\n    #change county in output\n    if \"Collier\" in example[\"output_text\"]:\n        example[\"output_text\"] = example[\"output_text\"].replace(\"Collier\", counties_to_sample[sample_id])\n        example[\"output_text\"] = example[\"output_text\"].replace(\"FL\", states_to_sample[sample_id])\n\n        if example[\"label\"] == 1:\n            if random.choice([0, 1, 2]) == 1:\n\n                random_counties = idx.copy()\n                random_counties.remove(sample_id)\n\n                example[\"output_text\"] = example[\"output_text\"].replace(\"Collier\", counties_to_sample[random.choice(random_counties)])\n                example[\"output_text\"] = example[\"output_text\"].replace(\"FL\", states_to_sample[random.choice(idx)])\n                \n                \n                example[\"label\"] =0\n\n    return example\ncos_ds[\"train\"] = cos_ds[\"train\"].map(country_change)",
   "metadata": {
    "_uuid": "7f21f059-77d3-419c-8e56-fc62f6aabb46",
    "_cell_guid": "de48ef36-a8c1-4b33-8960-6c64d35dd69d",
    "trusted": true,
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-30T11:17:38.355645Z",
     "start_time": "2025-10-30T11:17:38.186624Z"
    },
    "execution": {
     "iopub.status.busy": "2025-10-30T12:57:35.824470Z",
     "iopub.execute_input": "2025-10-30T12:57:35.824680Z",
     "iopub.status.idle": "2025-10-30T12:57:35.976194Z",
     "shell.execute_reply.started": "2025-10-30T12:57:35.824665Z",
     "shell.execute_reply": "2025-10-30T12:57:35.975389Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# import torch\n# from sentence_transformers import SentenceTransformer\n#\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n#\n# model_id = \"google/embeddinggemma-300M\"\n# model = SentenceTransformer(model_id).to(device=device)\n# label_embeddings = model.encode((new_ds[\"train\"]['input_text'][1], new_ds[\"train\"]['output_text'][1]), prompt_name=\"STS\")\n# similarities = model.similarity(label_embeddings[0], label_embeddings[1])\n# similarities",
   "metadata": {
    "_uuid": "03be039f-86bd-4935-88d6-8085fe37ced4",
    "_cell_guid": "e85dc482-4747-46a0-9d32-6f1137810cfe",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-24T14:47:44.984036Z",
     "iopub.execute_input": "2025-10-24T14:47:44.984300Z",
     "iopub.status.idle": "2025-10-24T14:47:45.222473Z",
     "shell.execute_reply.started": "2025-10-24T14:47:44.984282Z",
     "shell.execute_reply": "2025-10-24T14:47:45.221615Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-24T18:54:45.827747Z",
     "start_time": "2025-10-24T18:54:44.881765Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "#model.prompts",
   "metadata": {
    "_uuid": "135a5846-860f-4f87-952e-0a0ac249b579",
    "_cell_guid": "9f77d103-c75c-48ca-ba49-f797e754c707",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-24T14:44:28.889417Z",
     "iopub.execute_input": "2025-10-24T14:44:28.890206Z",
     "iopub.status.idle": "2025-10-24T14:44:28.895047Z",
     "shell.execute_reply.started": "2025-10-24T14:44:28.890174Z",
     "shell.execute_reply": "2025-10-24T14:44:28.894311Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# import wandb\n",
    "# wandb.init(mode=\"disabled\")"
   ],
   "metadata": {
    "_uuid": "81215a14-79e7-41c2-b721-0c091efdf7fd",
    "_cell_guid": "a07b9515-b7ef-45ba-a3c4-cd929d7ff9ea",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T12:57:40.154610Z",
     "iopub.execute_input": "2025-10-30T12:57:40.154854Z",
     "iopub.status.idle": "2025-10-30T12:57:49.502552Z",
     "shell.execute_reply.started": "2025-10-30T12:57:40.154837Z",
     "shell.execute_reply": "2025-10-30T12:57:49.500778Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from enum import Enum\nimport torch.nn.functional as F\nclass SiameseDistanceMetric(Enum):\n    EUCLIDEAN = lambda x, y: F.pairwise_distance(x, y, p=2)\n    MANHATTAN = lambda x, y: F.pairwise_distance(x, y, p=1)\n    COSINE_DISTANCE = lambda x, y: 1 - F.cosine_similarity(x, y)\n    CUSTOM_LOSS = lambda x, y: 1 - F.cosine_similarity(x, y) + torch.linalg.norm((x-y), ord = torch.inf, dim = 1)",
   "metadata": {
    "_uuid": "28d381fb-0299-414d-8398-1c55798ea085",
    "_cell_guid": "b20736aa-d6da-403c-bed0-f918a25597be",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T12:57:49.503501Z",
     "iopub.execute_input": "2025-10-30T12:57:49.503976Z",
     "iopub.status.idle": "2025-10-30T12:57:51.122177Z",
     "shell.execute_reply.started": "2025-10-30T12:57:49.503951Z",
     "shell.execute_reply": "2025-10-30T12:57:51.121407Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from sentence_transformers import losses\nfrom sentence_transformers.training_args import BatchSamplers\nfrom sentence_transformers import (\n    sampler,\n    SentenceTransformer,\n    SentenceTransformerModelCardData,\n    SentenceTransformerTrainer,\n    SentenceTransformerTrainingArguments,\n)\nfrom sentence_transformers.evaluation import BinaryClassificationEvaluator, TripletEvaluator\nimport torch\nmodel = SentenceTransformer(\n    \"google/embeddinggemma-300m\",\n    model_card_data=SentenceTransformerModelCardData(\n        language=\"en\",\n        license=\"apache-2.0\",\n        model_name=\"EmbeddingGemma-300m trained to measure coverage\",\n    ),\n)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\n# loss = losses.BatchAllTripletLoss( #only if vram is big enough!\n#     model=model,\n#     distance_metric=losses.BatchHardTripletLossDistanceFunction.cosine_distance,\n#     #margin=0.2\n# )\n\nloss = losses.ContrastiveLoss(\n    model=model,\n    distance_metric=SiameseDistanceMetric.COSINE_DISTANCE,#.EUCLIDEAN, #.MANHATTAN,\n    margin = 0.1,\n    size_average = True,\n)\n# loss = losses.CosineSimilarityLoss(\n#     model = model\n# )\n\nloss = losses.MatryoshkaLoss(\n    model = model,\n    loss = loss,\n    matryoshka_dims = [768, 512, 256, 128]\n)\n\nrun_name = \"embeddinggemma-300m-haystack-0.8k_contrastive\"\nprompt_use = \"STS\"\nargs = SentenceTransformerTrainingArguments(\n    report_to=None,\n    output_dir=f\"models/{run_name}\",\n    \n    num_train_epochs=5,\n    per_device_train_batch_size=3, # if you have enough vram, then set to |positive| + |semi_hard_negative| else change dataset structure and train objective\n    per_device_eval_batch_size=3,\n    gradient_accumulation_steps = 2,\n    learning_rate=2e-5,\n    warmup_ratio=0.05,\n    fp16=True,\n    bf16=False,\n    batch_sampler= BatchSamplers.BATCH_SAMPLER, #GROUP_BY_LABEL, #batchtriplet\n    prompts={\n        #\"text\": prompt_use,\n        \"input_text\": prompt_use,\n        \"output_text\": prompt_use\n    },\n    # Optional tracking/debugging parameters:\n    eval_strategy=\"steps\",\n    eval_steps=40,\n    save_strategy=\"epoch\",\n    #save_steps=80,\n)\n# test_evaluator = TripletEvaluator(\n#     anchors=new_ds[\"test\"][\"input_text\"],\n#     positives=new_ds[\"test\"][\"output_text\"],\n#     negatives=new_ds[\"test\"][\"failed_text\"],\n#     name=\"test\",\n# )\ncos_evaluator = BinaryClassificationEvaluator(\n    sentences1=cos_eval[\"input_text\"],\n    sentences2=cos_eval[\"output_text\"],\n    labels=cos_eval[\"label\"],\n    #for l2\n    #similarity_fn_names = [\"euclidean\"],\n)",
   "metadata": {
    "_uuid": "a498e465-992a-4bb1-9a6c-d971367d8bc6",
    "_cell_guid": "78467d9f-2581-48d3-a27c-0b8d1803eb07",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T12:58:18.122742Z",
     "iopub.execute_input": "2025-10-30T12:58:18.123021Z",
     "iopub.status.idle": "2025-10-30T12:58:47.427486Z",
     "shell.execute_reply.started": "2025-10-30T12:58:18.123000Z",
     "shell.execute_reply": "2025-10-30T12:58:47.426570Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-24T19:12:15.332468Z",
     "start_time": "2025-10-24T19:12:05.985001Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "trainer = SentenceTransformerTrainer(\n    model=model,\n    args=args,\n    train_dataset=cos_ds[\"train\"], #new_ds\n    eval_dataset=None,\n    loss=loss,\n    evaluator=cos_evaluator,\n)\ntrainer.train()",
   "metadata": {
    "_uuid": "0068dd0a-2b1e-4cff-b5ed-5bd06d328ecb",
    "_cell_guid": "ec65da79-e2d4-4a78-b5b2-0ec32ea932dc",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T12:58:56.208251Z",
     "iopub.execute_input": "2025-10-30T12:58:56.209433Z",
     "iopub.status.idle": "2025-10-30T13:28:03.441498Z",
     "shell.execute_reply.started": "2025-10-30T12:58:56.209406Z",
     "shell.execute_reply": "2025-10-30T13:28:03.440627Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-24T19:15:17.844478Z",
     "start_time": "2025-10-24T19:12:15.337863Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# results = test_evaluator(model)\n# print(results)",
   "metadata": {
    "_uuid": "661cc30d-f7b4-47bd-9ddb-5dd4d34d0dd3",
    "_cell_guid": "9dae6991-3253-4729-9639-fa4b24025c4e",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-25T23:37:55.762139Z",
     "iopub.execute_input": "2025-10-25T23:37:55.762767Z",
     "iopub.status.idle": "2025-10-25T23:38:31.550701Z",
     "shell.execute_reply.started": "2025-10-25T23:37:55.762743Z",
     "shell.execute_reply": "2025-10-25T23:38:31.549881Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "#model = SentenceTransformer(model_name_or_path = \"/kaggle/working/models/embeddinggemma-300m-haystack-0.8k_contrastive/checkpoint-400\")",
   "metadata": {
    "_uuid": "22767f42-3b8c-4614-afb8-2cb66641ab5d",
    "_cell_guid": "63e15774-bc3b-4a55-834f-23ad087019f5",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-27T14:18:28.824018Z",
     "iopub.execute_input": "2025-10-27T14:18:28.824525Z",
     "iopub.status.idle": "2025-10-27T14:18:31.124531Z",
     "shell.execute_reply.started": "2025-10-27T14:18:28.824503Z",
     "shell.execute_reply": "2025-10-27T14:18:31.123928Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "binary_results = cos_evaluator(model)\nbinary_results",
   "metadata": {
    "_uuid": "8ca9a70d-02e4-4420-ae47-1d2a5d19fcd8",
    "_cell_guid": "cad14b28-8a83-4949-a2d6-fab13a3cc4d3",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T13:28:09.325806Z",
     "iopub.execute_input": "2025-10-30T13:28:09.326412Z",
     "iopub.status.idle": "2025-10-30T13:28:23.894901Z",
     "shell.execute_reply.started": "2025-10-30T13:28:09.326388Z",
     "shell.execute_reply": "2025-10-30T13:28:23.894048Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "sims = []\nlabels = cos_eval[\"label\"]\nfor row in cos_eval:\n    label_embeddings = model.encode((row['input_text'], row['output_text']), \n                                    prompt_name=prompt_use, \n                                    show_progress_bar = False,\n                                    #if l2\n                                    #convert_to_numpy = False\n                                   )\n    #for cos\n    similarities = model.similarity(label_embeddings[0], label_embeddings[1])\n    #for l2 also could just change atribute in model object that sets up defalut distance function for .similiarity()\n    #similarities = torch.nn.functional.pairwise_distance(label_embeddings[0], label_embeddings[1])\n    sims.append(similarities)",
   "metadata": {
    "_uuid": "072f18c1-3d63-41c3-817f-b7849a3022ac",
    "_cell_guid": "6f39ed6d-17d2-41a7-b17f-4560776f3ef8",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T13:29:28.996219Z",
     "iopub.execute_input": "2025-10-30T13:29:28.996980Z",
     "iopub.status.idle": "2025-10-30T13:29:51.461657Z",
     "shell.execute_reply.started": "2025-10-30T13:29:28.996950Z",
     "shell.execute_reply": "2025-10-30T13:29:51.460808Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "sims = torch.tensor(sims)",
   "metadata": {
    "_uuid": "65bf3660-9c67-403f-89c1-02953d4661cb",
    "_cell_guid": "60530c10-0afc-4e43-9435-ab5099c5f711",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T13:29:51.462991Z",
     "iopub.execute_input": "2025-10-30T13:29:51.463766Z",
     "iopub.status.idle": "2025-10-30T13:29:51.467845Z",
     "shell.execute_reply.started": "2025-10-30T13:29:51.463739Z",
     "shell.execute_reply": "2025-10-30T13:29:51.467299Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfpr, tpr, thresholds =roc_curve(np.array(cos_eval[\"label\"][:],dtype = float), sims.detach().cpu().numpy())\nprint(roc_auc_score(np.array(cos_eval[\"label\"][:],dtype = float), sims.detach().cpu().numpy()))",
   "metadata": {
    "_uuid": "4747cf37-6f9a-4408-843e-a662baed3d89",
    "_cell_guid": "71999c04-0578-40ca-adc2-b47d47cc6b0b",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T13:29:51.468700Z",
     "iopub.execute_input": "2025-10-30T13:29:51.468985Z",
     "iopub.status.idle": "2025-10-30T13:29:51.489103Z",
     "shell.execute_reply.started": "2025-10-30T13:29:51.468942Z",
     "shell.execute_reply": "2025-10-30T13:29:51.488391Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nplt.plot(fpr, tpr)",
   "metadata": {
    "_uuid": "d00ffb5a-2e85-433c-aa4e-b5f959ae8502",
    "_cell_guid": "baab7aa5-cb51-4d48-9d1f-0124f77b3a8c",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-30T13:29:51.490306Z",
     "iopub.execute_input": "2025-10-30T13:29:51.490500Z",
     "iopub.status.idle": "2025-10-30T13:29:51.728421Z",
     "shell.execute_reply.started": "2025-10-30T13:29:51.490486Z",
     "shell.execute_reply": "2025-10-30T13:29:51.727862Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# final_output_dir = f\"models/{run_name}/final\"\n# model.save_pretrained(final_output_dir)\n\nmodel.push_to_hub(\"mancer146/embeddinggemma-300m-haystack-contrastive-thin-fixed\", commit_message = \"0_0\")",
   "metadata": {
    "_uuid": "4f6d67b6-800e-4d37-af15-af98956c01c2",
    "_cell_guid": "0b979c7d-a560-4448-935c-80a434b7216e",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2025-10-27T16:01:36.926711Z",
     "iopub.execute_input": "2025-10-27T16:01:36.927255Z",
     "iopub.status.idle": "2025-10-27T16:01:59.323699Z",
     "shell.execute_reply.started": "2025-10-27T16:01:36.927232Z",
     "shell.execute_reply": "2025-10-27T16:01:59.323054Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
